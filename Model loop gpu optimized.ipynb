{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057cae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.random import seed # to set seed\n",
    "from tensorflow.random import set_seed # to set seed\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe0beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply seed\n",
    "seed_value = 1338\n",
    "set_seed(seed_value)\n",
    "seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e26a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c07dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ca9705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b04dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda activate -n gpu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1843032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2076 images belonging to 2 classes.\n",
      "Found 258 images belonging to 2 classes.\n",
      "Found 262 images belonging to 2 classes.\n",
      "Found 2076 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Kopieret fra model_2.py 4/11 ~~11.30\n",
    "#%% ImageDataGenerator\n",
    "\n",
    "image_size = [200, 200]\n",
    "batch = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip= True,\n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_gen = test_datagen.flow_from_directory(\n",
    "        'val',\n",
    "        target_size=image_size,\n",
    "        batch_size=batch,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    'test',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch,\n",
    "    class_mode='binary')\n",
    "\n",
    "#%% Visualizing ImageDataGenerator augmentation\n",
    "train_datagen_viz = ImageDataGenerator(rotation_range=40,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip= True,\n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1)\n",
    "\n",
    "train_gen_viz = train_datagen_viz.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=image_size,\n",
    "    color_mode='rgb',\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    seed=1337)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15,15))\n",
    "\n",
    "for i in range(4):\n",
    "    image = next(train_gen_viz)[0].astype('uint8')\n",
    "    \n",
    "    image = np.squeeze(image)\n",
    "    \n",
    "    ax[i].imshow(image)\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d00bc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units\n",
    "con_layer_1 = [16]\n",
    "con_layer_2 = [32]\n",
    "con_layer_3 = [32]\n",
    "act_funcs = ['relu', 'selu', 'elu', 'tanh', 'sigmoid']\n",
    "hidden_layer_1 = [512]\n",
    "dropout_sizes = [0.2]\n",
    "optimizers = [\"adam\"]\n",
    "epoch_n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccae95c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 625 parameter combinations and 10 epochs\n"
     ]
    }
   ],
   "source": [
    "# Number of models to be created:\n",
    "model_count = len(con_layer_1) * len(con_layer_2) * len(con_layer_3) * len(act_funcs) * len(act_funcs) * len(act_funcs) * len(act_funcs) * len(dropout_sizes) * len(optimizers) * len(hidden_layer_1)\n",
    "\n",
    "# Result array\n",
    "results = pd.DataFrame(columns = ['loss',\n",
    "                                  'val_loss',\n",
    "                                  'accuracy',\n",
    "                                  'val_accuracy',\n",
    "                                  'con_layer_1',\n",
    "                                  'con_layer_1_activation',\n",
    "                                  'con_layer_2',\n",
    "                                  'con_layer_2_activation',\n",
    "                                  'con_layer_3',\n",
    "                                  'con_layer_3_activation',\n",
    "                                  'hidden_layer_1',\n",
    "                                  'hidden_layer_1_activation',\n",
    "                                  'dropout_sizes',\n",
    "                                  'optimizers',\n",
    "                                  'epoch',\n",
    "                                  'epoch_n'])\n",
    "print(f\"There are {model_count} parameter combinations and {epoch_n} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06bba3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "results = pd.read_csv('loop_results.csv')\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3447c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped model 1 out of 625.\n",
      "Skipped model 2 out of 625.\n",
      "Skipped model 3 out of 625.\n",
      "Skipped model 4 out of 625.\n",
      "Skipped model 5 out of 625.\n",
      "Skipped model 6 out of 625.\n",
      "Skipped model 7 out of 625.\n",
      "Skipped model 8 out of 625.\n",
      "Skipped model 9 out of 625.\n",
      "Skipped model 10 out of 625.\n",
      "Skipped model 11 out of 625.\n",
      "Skipped model 12 out of 625.\n",
      "Skipped model 13 out of 625.\n",
      "Skipped model 14 out of 625.\n",
      "Skipped model 15 out of 625.\n",
      "Skipped model 16 out of 625.\n",
      "Skipped model 17 out of 625.\n",
      "Skipped model 18 out of 625.\n",
      "Skipped model 19 out of 625.\n",
      "Skipped model 20 out of 625.\n",
      "Skipped model 21 out of 625.\n",
      "Skipped model 22 out of 625.\n",
      "Skipped model 23 out of 625.\n",
      "Skipped model 24 out of 625.\n",
      "Skipped model 25 out of 625.\n",
      "Skipped model 26 out of 625.\n",
      "Skipped model 27 out of 625.\n",
      "Skipped model 28 out of 625.\n",
      "Skipped model 29 out of 625.\n",
      "Skipped model 30 out of 625.\n",
      "Skipped model 31 out of 625.\n",
      "Skipped model 32 out of 625.\n",
      "Skipped model 33 out of 625.\n",
      "Skipped model 34 out of 625.\n",
      "Skipped model 35 out of 625.\n",
      "Skipped model 36 out of 625.\n",
      "Skipped model 37 out of 625.\n",
      "Skipped model 38 out of 625.\n",
      "Skipped model 39 out of 625.\n",
      "Skipped model 40 out of 625.\n",
      "Skipped model 41 out of 625.\n",
      "Skipped model 42 out of 625.\n",
      "Skipped model 43 out of 625.\n",
      "Skipped model 44 out of 625.\n",
      "Skipped model 45 out of 625.\n",
      "Skipped model 46 out of 625.\n",
      "Skipped model 47 out of 625.\n",
      "Skipped model 48 out of 625.\n",
      "Skipped model 49 out of 625.\n",
      "Skipped model 50 out of 625.\n",
      "Skipped model 51 out of 625.\n",
      "Skipped model 52 out of 625.\n",
      "Skipped model 53 out of 625.\n",
      "Skipped model 54 out of 625.\n",
      "Skipped model 55 out of 625.\n",
      "Skipped model 56 out of 625.\n",
      "Skipped model 57 out of 625.\n",
      "Skipped model 58 out of 625.\n",
      "Skipped model 59 out of 625.\n",
      "Skipped model 60 out of 625.\n",
      "Skipped model 61 out of 625.\n",
      "Skipped model 62 out of 625.\n",
      "Skipped model 63 out of 625.\n",
      "Skipped model 64 out of 625.\n",
      "Skipped model 65 out of 625.\n",
      "Skipped model 66 out of 625.\n",
      "Skipped model 67 out of 625.\n",
      "Skipped model 68 out of 625.\n",
      "Skipped model 69 out of 625.\n",
      "Skipped model 70 out of 625.\n",
      "Skipped model 71 out of 625.\n",
      "Skipped model 72 out of 625.\n",
      "Skipped model 73 out of 625.\n",
      "Skipped model 74 out of 625.\n",
      "Skipped model 75 out of 625.\n",
      "Skipped model 76 out of 625.\n",
      "Skipped model 77 out of 625.\n",
      "Skipped model 78 out of 625.\n",
      "Skipped model 79 out of 625.\n",
      "Skipped model 80 out of 625.\n",
      "Skipped model 81 out of 625.\n",
      "Skipped model 82 out of 625.\n",
      "Skipped model 83 out of 625.\n",
      "Skipped model 84 out of 625.\n",
      "Skipped model 85 out of 625.\n",
      "Skipped model 86 out of 625.\n",
      "Skipped model 87 out of 625.\n",
      "Skipped model 88 out of 625.\n",
      "Skipped model 89 out of 625.\n",
      "Skipped model 90 out of 625.\n",
      "Skipped model 91 out of 625.\n",
      "Skipped model 92 out of 625.\n",
      "Skipped model 93 out of 625.\n",
      "Skipped model 94 out of 625.\n",
      "Skipped model 95 out of 625.\n",
      "Skipped model 96 out of 625.\n",
      "Skipped model 97 out of 625.\n",
      "Skipped model 98 out of 625.\n",
      "Skipped model 99 out of 625.\n",
      "Skipped model 100 out of 625.\n",
      "Skipped model 101 out of 625.\n",
      "Skipped model 102 out of 625.\n",
      "Skipped model 103 out of 625.\n",
      "Skipped model 104 out of 625.\n",
      "Skipped model 105 out of 625.\n",
      "Skipped model 106 out of 625.\n",
      "Skipped model 107 out of 625.\n",
      "Skipped model 108 out of 625.\n",
      "Skipped model 109 out of 625.\n",
      "Skipped model 110 out of 625.\n",
      "Skipped model 111 out of 625.\n",
      "Skipped model 112 out of 625.\n",
      "Skipped model 113 out of 625.\n",
      "Skipped model 114 out of 625.\n",
      "Skipped model 115 out of 625.\n",
      "Skipped model 116 out of 625.\n",
      "Skipped model 117 out of 625.\n",
      "Skipped model 118 out of 625.\n",
      "Skipped model 119 out of 625.\n",
      "Skipped model 120 out of 625.\n",
      "Skipped model 121 out of 625.\n",
      "Skipped model 122 out of 625.\n",
      "Skipped model 123 out of 625.\n",
      "Skipped model 124 out of 625.\n",
      "Skipped model 125 out of 625.\n",
      "Skipped model 126 out of 625.\n",
      "Skipped model 127 out of 625.\n",
      "Skipped model 128 out of 625.\n",
      "Skipped model 129 out of 625.\n",
      "Skipped model 130 out of 625.\n",
      "Skipped model 131 out of 625.\n",
      "Skipped model 132 out of 625.\n",
      "Skipped model 133 out of 625.\n",
      "Skipped model 134 out of 625.\n",
      "Skipped model 135 out of 625.\n",
      "Skipped model 136 out of 625.\n",
      "Skipped model 137 out of 625.\n",
      "Skipped model 138 out of 625.\n",
      "Skipped model 139 out of 625.\n",
      "Skipped model 140 out of 625.\n",
      "Skipped model 141 out of 625.\n",
      "Skipped model 142 out of 625.\n",
      "Skipped model 143 out of 625.\n",
      "Skipped model 144 out of 625.\n",
      "Skipped model 145 out of 625.\n",
      "Skipped model 146 out of 625.\n",
      "Skipped model 147 out of 625.\n",
      "Skipped model 148 out of 625.\n",
      "Skipped model 149 out of 625.\n",
      "Skipped model 150 out of 625.\n",
      "Skipped model 151 out of 625.\n",
      "Skipped model 152 out of 625.\n",
      "Skipped model 153 out of 625.\n",
      "Skipped model 154 out of 625.\n",
      "Skipped model 155 out of 625.\n",
      "Skipped model 156 out of 625.\n",
      "Skipped model 157 out of 625.\n",
      "Skipped model 158 out of 625.\n",
      "Skipped model 159 out of 625.\n",
      "Skipped model 160 out of 625.\n",
      "Skipped model 161 out of 625.\n",
      "Skipped model 162 out of 625.\n",
      "Skipped model 163 out of 625.\n",
      "Skipped model 164 out of 625.\n",
      "Skipped model 165 out of 625.\n",
      "Skipped model 166 out of 625.\n",
      "Skipped model 167 out of 625.\n",
      "Skipped model 168 out of 625.\n",
      "Skipped model 169 out of 625.\n",
      "Skipped model 170 out of 625.\n",
      "Skipped model 171 out of 625.\n",
      "Skipped model 172 out of 625.\n",
      "Skipped model 173 out of 625.\n",
      "Skipped model 174 out of 625.\n",
      "Skipped model 175 out of 625.\n",
      "Skipped model 176 out of 625.\n",
      "Skipped model 177 out of 625.\n",
      "Skipped model 178 out of 625.\n",
      "Skipped model 179 out of 625.\n",
      "Skipped model 180 out of 625.\n",
      "Skipped model 181 out of 625.\n",
      "Skipped model 182 out of 625.\n",
      "Skipped model 183 out of 625.\n",
      "Skipped model 184 out of 625.\n",
      "Skipped model 185 out of 625.\n",
      "Skipped model 186 out of 625.\n",
      "Skipped model 187 out of 625.\n",
      "Skipped model 188 out of 625.\n",
      "Skipped model 189 out of 625.\n",
      "Skipped model 190 out of 625.\n",
      "Skipped model 191 out of 625.\n",
      "Skipped model 192 out of 625.\n",
      "Skipped model 193 out of 625.\n",
      "Skipped model 194 out of 625.\n",
      "Skipped model 195 out of 625.\n",
      "Skipped model 196 out of 625.\n",
      "Skipped model 197 out of 625.\n",
      "Skipped model 198 out of 625.\n",
      "Skipped model 199 out of 625.\n",
      "Skipped model 200 out of 625.\n",
      "Skipped model 201 out of 625.\n",
      "Skipped model 202 out of 625.\n",
      "Skipped model 203 out of 625.\n",
      "Skipped model 204 out of 625.\n",
      "Skipped model 205 out of 625.\n",
      "Skipped model 206 out of 625.\n",
      "Skipped model 207 out of 625.\n",
      "Skipped model 208 out of 625.\n",
      "Skipped model 209 out of 625.\n",
      "Skipped model 210 out of 625.\n",
      "Skipped model 211 out of 625.\n",
      "Skipped model 212 out of 625.\n",
      "Skipped model 213 out of 625.\n",
      "Skipped model 214 out of 625.\n",
      "Skipped model 215 out of 625.\n",
      "Skipped model 216 out of 625.\n",
      "Skipped model 217 out of 625.\n",
      "Skipped model 218 out of 625.\n",
      "Skipped model 219 out of 625.\n",
      "Skipped model 220 out of 625.\n",
      "Skipped model 221 out of 625.\n",
      "Skipped model 222 out of 625.\n",
      "Skipped model 223 out of 625.\n",
      "Skipped model 224 out of 625.\n",
      "Skipped model 225 out of 625.\n",
      "Skipped model 226 out of 625.\n",
      "Skipped model 227 out of 625.\n",
      "Skipped model 228 out of 625.\n",
      "Skipped model 229 out of 625.\n",
      "Skipped model 230 out of 625.\n",
      "Skipped model 231 out of 625.\n",
      "Skipped model 232 out of 625.\n",
      "Skipped model 233 out of 625.\n",
      "Skipped model 234 out of 625.\n",
      "Skipped model 235 out of 625.\n",
      "Skipped model 236 out of 625.\n",
      "Skipped model 237 out of 625.\n",
      "Skipped model 238 out of 625.\n",
      "Skipped model 239 out of 625.\n",
      "Skipped model 240 out of 625.\n",
      "Skipped model 241 out of 625.\n",
      "Skipped model 242 out of 625.\n",
      "Skipped model 243 out of 625.\n",
      "Skipped model 244 out of 625.\n",
      "Skipped model 245 out of 625.\n",
      "Skipped model 246 out of 625.\n",
      "Skipped model 247 out of 625.\n",
      "Skipped model 248 out of 625.\n",
      "Skipped model 249 out of 625.\n",
      "Skipped model 250 out of 625.\n",
      "Skipped model 251 out of 625.\n",
      "Skipped model 252 out of 625.\n",
      "Skipped model 253 out of 625.\n",
      "Skipped model 254 out of 625.\n",
      "Training model 255 out of 625.\n",
      "WARNING:tensorflow:From C:\\Users\\Max\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "Training model 256 out of 625.\n",
      "Training model 257 out of 625.\n",
      "Training model 258 out of 625.\n",
      "Training model 259 out of 625.\n",
      "Training model 260 out of 625.\n",
      "Training model 261 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6862s vs `on_train_batch_end` time: 1.0557s). Check your callbacks.\n",
      "Training model 262 out of 625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 263 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6892s vs `on_train_batch_end` time: 1.0920s). Check your callbacks.\n",
      "Training model 264 out of 625.\n",
      "Training model 265 out of 625.\n",
      "Training model 266 out of 625.\n",
      "Training model 267 out of 625.\n",
      "Training model 268 out of 625.\n",
      "Training model 269 out of 625.\n",
      "Training model 270 out of 625.\n",
      "Training model 271 out of 625.\n",
      "Training model 272 out of 625.\n",
      "Training model 273 out of 625.\n",
      "Training model 274 out of 625.\n",
      "Training model 275 out of 625.\n",
      "Training model 276 out of 625.\n",
      "Training model 277 out of 625.\n",
      "Training model 278 out of 625.\n",
      "Training model 279 out of 625.\n",
      "Training model 280 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7091s vs `on_train_batch_end` time: 1.1216s). Check your callbacks.\n",
      "Training model 281 out of 625.\n",
      "Training model 282 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7440s vs `on_train_batch_end` time: 1.1173s). Check your callbacks.\n",
      "Training model 283 out of 625.\n",
      "Training model 284 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7141s vs `on_train_batch_end` time: 1.0874s). Check your callbacks.\n",
      "Training model 285 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7181s vs `on_train_batch_end` time: 1.1158s). Check your callbacks.\n",
      "Training model 286 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7301s vs `on_train_batch_end` time: 1.1393s). Check your callbacks.\n",
      "Training model 287 out of 625.\n",
      "Training model 288 out of 625.\n",
      "Training model 289 out of 625.\n",
      "Training model 290 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7151s vs `on_train_batch_end` time: 1.1045s). Check your callbacks.\n",
      "Training model 291 out of 625.\n",
      "Training model 292 out of 625.\n",
      "Training model 293 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7051s vs `on_train_batch_end` time: 1.0917s). Check your callbacks.\n",
      "Training model 294 out of 625.\n",
      "Training model 295 out of 625.\n",
      "Training model 296 out of 625.\n",
      "Training model 297 out of 625.\n",
      "Training model 298 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7121s vs `on_train_batch_end` time: 1.1368s). Check your callbacks.\n",
      "Training model 299 out of 625.\n",
      "Training model 300 out of 625.\n",
      "Training model 301 out of 625.\n",
      "Training model 302 out of 625.\n",
      "Training model 303 out of 625.\n",
      "Training model 304 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6134s vs `on_train_batch_end` time: 1.1501s). Check your callbacks.\n",
      "Training model 305 out of 625.\n",
      "Training model 306 out of 625.\n",
      "Training model 307 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7231s vs `on_train_batch_end` time: 1.1303s). Check your callbacks.\n",
      "Training model 308 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7441s vs `on_train_batch_end` time: 1.1574s). Check your callbacks.\n",
      "Training model 309 out of 625.\n",
      "Training model 310 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7259s vs `on_train_batch_end` time: 1.1321s). Check your callbacks.\n",
      "Training model 311 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7325s vs `on_train_batch_end` time: 1.1637s). Check your callbacks.\n",
      "Training model 312 out of 625.\n",
      "Training model 313 out of 625.\n",
      "Training model 314 out of 625.\n",
      "Training model 315 out of 625.\n",
      "Training model 316 out of 625.\n",
      "Training model 317 out of 625.\n",
      "Training model 318 out of 625.\n",
      "Training model 319 out of 625.\n",
      "Training model 320 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7330s vs `on_train_batch_end` time: 1.1062s). Check your callbacks.\n",
      "Training model 321 out of 625.\n",
      "Training model 322 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7201s vs `on_train_batch_end` time: 1.1787s). Check your callbacks.\n",
      "Training model 323 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7861s vs `on_train_batch_end` time: 1.1936s). Check your callbacks.\n",
      "Training model 324 out of 625.\n",
      "Training model 325 out of 625.\n",
      "Training model 326 out of 625.\n",
      "Training model 327 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7320s vs `on_train_batch_end` time: 1.1848s). Check your callbacks.\n",
      "Training model 328 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7470s vs `on_train_batch_end` time: 1.1412s). Check your callbacks.\n",
      "Training model 329 out of 625.\n",
      "Training model 330 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7380s vs `on_train_batch_end` time: 1.1888s). Check your callbacks.\n",
      "Training model 331 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7879s vs `on_train_batch_end` time: 1.1911s). Check your callbacks.\n",
      "Training model 332 out of 625.\n",
      "Training model 333 out of 625.\n",
      "Training model 334 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7769s vs `on_train_batch_end` time: 1.1741s). Check your callbacks.\n",
      "Training model 335 out of 625.\n",
      "Training model 336 out of 625.\n",
      "Training model 337 out of 625.\n",
      "Training model 338 out of 625.\n",
      "Training model 339 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7370s vs `on_train_batch_end` time: 1.2081s). Check your callbacks.\n",
      "Training model 340 out of 625.\n",
      "Training model 341 out of 625.\n",
      "Training model 342 out of 625.\n",
      "Training model 343 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7558s vs `on_train_batch_end` time: 1.2119s). Check your callbacks.\n",
      "Training model 344 out of 625.\n",
      "Training model 345 out of 625.\n",
      "Training model 346 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7498s vs `on_train_batch_end` time: 1.1731s). Check your callbacks.\n",
      "Training model 347 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7540s vs `on_train_batch_end` time: 1.2014s). Check your callbacks.\n",
      "Training model 348 out of 625.\n",
      "Training model 349 out of 625.\n",
      "Training model 350 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7310s vs `on_train_batch_end` time: 1.1974s). Check your callbacks.\n",
      "Training model 351 out of 625.\n",
      "Training model 352 out of 625.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7001s vs `on_train_batch_end` time: 1.1392s). Check your callbacks.\n",
      "Training model 353 out of 625.\n",
      "Training model 354 out of 625.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-902bed33454e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                                         \u001b[1;31m# Fitting model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                                         history = model.fit(\n\u001b[0m\u001b[0;32m     91\u001b[0m                                             \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                                             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop tracking\n",
    "count = 0 # To count loops\n",
    "# Model loop\n",
    "for con1 in con_layer_1:\n",
    "    for con1_act in act_funcs:\n",
    "        for con2 in con_layer_2:\n",
    "            if(con1*3<con2):\n",
    "                continue\n",
    "            for con2_act in act_funcs:\n",
    "                for con3 in con_layer_3:\n",
    "                    if(con2*3<con3):\n",
    "                        continue\n",
    "                    for con3_act in act_funcs:\n",
    "                        for hidden1 in hidden_layer_1:\n",
    "                            for hidden1_act in act_funcs:\n",
    "                                for dropout_size in dropout_sizes:\n",
    "                                    for optimizer in optimizers:\n",
    "                                        # Count and print progress\n",
    "                                        count = count+1\n",
    "                                        \n",
    "                                        \n",
    "                                        # Check if combination has been used\n",
    "                                        if(len(results.loc[(results['con_layer_1'] == con1) &\n",
    "                                                           (results['con_layer_1_activation'] <= con1_act) &\n",
    "                                                           (results['con_layer_2'] == con2) &\n",
    "                                                           (results['con_layer_2_activation'] == con2_act) &\n",
    "                                                           (results['con_layer_3'] == con3) &\n",
    "                                                           (results['con_layer_3_activation'] == con3_act) &\n",
    "                                                           (results['hidden_layer_1'] == hidden1) &\n",
    "                                                           (results['hidden_layer_1_activation'] == hidden1_act) &\n",
    "                                                           (results['dropout_sizes'] == dropout_size) &\n",
    "                                                           (results['optimizers'] == optimizer) &\n",
    "                                                           (results['epoch_n'] <= epoch_n)])):\n",
    "                                            print(f\"Skipped model {count} out of {model_count}.\")\n",
    "                                            continue\n",
    "                                        else:\n",
    "                                            print(f'Training model {count} out of {model_count}.')\n",
    "                                        # Model baseret pÃ¥ model.py kopieret 04/11 ~11.30\n",
    "                                        model = keras.Sequential([\n",
    "                                            # First convolution\n",
    "                                            layers.Conv2D(con1, (3,3), activation=con1_act, input_shape=(200, 200, 3)),\n",
    "                                            layers.MaxPooling2D(2,2), # halving the image size \n",
    "\n",
    "                                            # Second convolution\n",
    "                                            layers.Conv2D(con2, (3,3), activation=con2_act),\n",
    "                                            layers.MaxPooling2D(2,2),\n",
    "\n",
    "                                            # Third convolution\n",
    "                                            layers.Conv2D(con3, (3,3), activation=con3_act),\n",
    "                                            layers.MaxPooling2D(2,2),\n",
    "\n",
    "                                            # Fourth convolution - hidden until after some finetuning\n",
    "                                            #layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                                            #layers.MaxPooling2D(2,2),\n",
    "\n",
    "                                            # Fifth convolution - hidden until after some finetuning\n",
    "                                            #layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                                            #layers.MaxPooling2D(2,2),\n",
    "\n",
    "                                            # Flatten results to feed into a Deep Nerual Net\n",
    "                                            layers.Flatten(),\n",
    "\n",
    "                                            # 512 neuron hidden layer\n",
    "                                            layers.Dense(hidden1, activation=hidden1_act),\n",
    "                                            \n",
    "                                            # Dropout NEW!!!!!!\n",
    "                                            layers.Dropout(dropout_size),\n",
    "\n",
    "                                            # Binary output layer\n",
    "                                            layers.Dense(1, activation='sigmoid')\n",
    "                                            ])\n",
    "\n",
    "                                        #model.summary() # model summary\n",
    "\n",
    "                                        model.compile(\n",
    "                                            loss='binary_crossentropy',\n",
    "                                            optimizer=optimizer,\n",
    "                                            metrics=['accuracy']) # compiling model\n",
    "                                        \n",
    "                                        # Model fitting fra model_2.py kopieret 4/11 ~11.30\n",
    "                                        # Callbacks for tensorboard \n",
    "                                        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\") # tensorboard --logdir ./logs\n",
    "\n",
    "                                        # Step sizes for train, validation and testing\n",
    "                                        STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
    "                                        STEP_SIZE_VAL=val_gen.n//val_gen.batch_size\n",
    "                                        STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
    "\n",
    "                                        # Fitting model\n",
    "                                        history = model.fit(\n",
    "                                            train_gen,\n",
    "                                            steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                            epochs=epoch_n, # for at spare lidt tid\n",
    "                                            validation_data=val_gen,\n",
    "                                            validation_steps=STEP_SIZE_VAL,\n",
    "                                            callbacks=[tensorboard_callback],\n",
    "                                            verbose = False)\n",
    "                                        \n",
    "                                        # Get results (from history)\n",
    "                                        history = history.history\n",
    "                                        \n",
    "                                        # Append each epoch\n",
    "                                        for h in range(len(history['loss'])):\n",
    "                                            row = {'loss':history['loss'][h],\n",
    "                                                   'val_loss':history['val_loss'][h],\n",
    "                                                   'accuracy':history['accuracy'][h],\n",
    "                                                   'val_accuracy': history['val_accuracy'][h],\n",
    "                                                   'con_layer_1': con1,\n",
    "                                                   'con_layer_1_activation': con1_act,\n",
    "                                                   'con_layer_2': con2,\n",
    "                                                   'con_layer_2_activation': con2_act,\n",
    "                                                   'con_layer_3': con3,\n",
    "                                                   'con_layer_3_activation': con3_act,\n",
    "                                                   'hidden_layer_1': hidden1,\n",
    "                                                   'hidden_layer_1_activation': hidden1_act,\n",
    "                                                   'dropout_sizes': dropout_size,\n",
    "                                                   'optimizers': optimizer,\n",
    "                                                   'epoch': (h+1),\n",
    "                                                   'epoch_n': epoch_n}\n",
    "                                            results = results.append(row, ignore_index=True)\n",
    "                                        results.to_csv('loop_results.csv',index=False)\n",
    "\n",
    "print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4dd128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "results.to_csv('loop_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(tf-gpu-2.3.0)",
   "language": "python",
   "name": "tf-gpu-2.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
